{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oiu2iV7XwzNc"
      },
      "outputs": [],
      "source": [
        "#imports libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, r2_score, mean_squared_error, mean_absolute_error,precision_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"class Package:\n",
        "\n",
        "    def __init__(self, problem_statement=\"classification\", target_column=None):\n",
        "        self.problem_statement = problem_statement\n",
        "        self.target_column = target_column\n",
        "\n",
        "        self.preprocessor = None\n",
        "        self.task_type = None\n",
        "        self.results_df = None\n",
        "\n",
        "    # DATA CLEANING\n",
        "    def clean_data(self, data):\n",
        "\n",
        "        data = data.copy()\n",
        "        data = data.drop_duplicates()\n",
        "\n",
        "        for col in data.columns:\n",
        "            if data[col].dtype in [\"int64\", \"float64\"]:\n",
        "                data[col].fillna(data[col].mean(), inplace=True)\n",
        "            else:\n",
        "                if len(data[col].mode()) > 0:\n",
        "                    data[col].fillna(data[col].mode()[0], inplace=True)\n",
        "                else:\n",
        "                    data[col].fillna(\"missing\", inplace=True)\n",
        "\n",
        "        return data\n",
        "\n",
        "    # DATA SPLITTING\n",
        "    def Data_splitting(self, X, y):\n",
        "\n",
        "        return train_test_split(\n",
        "            X,\n",
        "            y,\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    # PREPROCESSING (ENCODING + SCALING)\n",
        "\n",
        "    def Preprocess(self, X_train, X_test=None):\n",
        "\n",
        "        num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "        cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "        self.preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                (\"num\", StandardScaler(), num_cols),\n",
        "                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        X_train_processed = self.preprocessor.fit_transform(X_train)\n",
        "\n",
        "        if X_test is not None:\n",
        "            X_test_processed = self.preprocessor.transform(X_test)\n",
        "            return X_train_processed, X_test_processed\n",
        "\n",
        "        return X_train_processed\n",
        "\n",
        "\n",
        "    def model_design(self, data):\n",
        "\n",
        "        # ------------------------------\n",
        "        # CLEANING\n",
        "        # ------------------------------\n",
        "        data = self.clean_data(data)\n",
        "\n",
        "        X = data.drop(columns=[self.target_column])\n",
        "        y = data[self.target_column]\n",
        "\n",
        "        # ==================================================\n",
        "        # TODO 1: TASK DETECTION\n",
        "        # ASSIGNED TO: Shreyas\n",
        "        # Use:\n",
        "        # - y.dtype\n",
        "        # - y.nunique()\n",
        "        # Set:\n",
        "        # self.task_type = \"classification\" or \"regression\"\n",
        "        # ==================================================\n",
        "        # self.task_type = ?\n",
        "\n",
        "\n",
        "        # ------------------------------\n",
        "        # SPLIT DATA\n",
        "        # ------------------------------\n",
        "        X_train, X_test, y_train, y_test = self.Data_splitting(X, y)\n",
        "\n",
        "        # ------------------------------\n",
        "        # PREPROCESS DATA\n",
        "        # ------------------------------\n",
        "        X_train_p, X_test_p = self.Preprocess(X_train, X_test)\n",
        "\n",
        "\n",
        "        # ==================================================\n",
        "        # TODO 2: MODEL SELECTION\n",
        "        # ASSIGNED TO: Gourav\n",
        "        # Create a dictionary like:\n",
        "        # models = {\"Model Name\": model_object}\n",
        "        # Based on self.task_type\n",
        "        # ==================================================\n",
        "        # models = {}\n",
        "\n",
        "\n",
        "        # ==================================================\n",
        "        # TODO 3: MODEL TRAINING\n",
        "        # ASSIGNED TO: Monish\n",
        "        # For each model:\n",
        "        # - fit(X_train_p, y_train)\n",
        "        # - predict(X_test_p)\n",
        "        # Store predictions:\n",
        "        # predictions = {\"Model Name\": preds}\n",
        "        # ==================================================\n",
        "        # predictions = {}\n",
        "\n",
        "\n",
        "        # ==================================================\n",
        "        # TODO 4: MODEL EVALUATION\n",
        "        # ASSIGNED TO:\n",
        "        # Classification → Rajshekar\n",
        "        # Regression     → Rahul\n",
        "        # For each prediction:\n",
        "        # - calculate metrics\n",
        "        # - append dict to results list\n",
        "        # ==================================================\n",
        "        # results = []\n",
        "\n",
        "\n",
        "        # ==================================================\n",
        "        # TODO 5: MODEL COMPARISON\n",
        "        # ASSIGNED TO: Seshadri\n",
        "        # Steps:\n",
        "        # - Convert results to DataFrame\n",
        "        # - Sort by main metric\n",
        "        # - Extract best and top-2 models\n",
        "        # ==================================================\n",
        "        # self.results_df = ?\n",
        "        # best_model = ?\n",
        "        # top_2_models = ?\n",
        "        pass\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zbVRR1qhxe8W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "b40c0423-fc39-44d2-9103-d55bf076c3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'class Package:\\n\\n    def __init__(self, problem_statement=\"classification\", target_column=None):\\n        self.problem_statement = problem_statement\\n        self.target_column = target_column\\n\\n        self.preprocessor = None\\n        self.task_type = None\\n        self.results_df = None\\n\\n    # DATA CLEANING\\n    def clean_data(self, data):\\n\\n        data = data.copy()\\n        data = data.drop_duplicates()\\n\\n        for col in data.columns:\\n            if data[col].dtype in [\"int64\", \"float64\"]:\\n                data[col].fillna(data[col].mean(), inplace=True)\\n            else:\\n                if len(data[col].mode()) > 0:\\n                    data[col].fillna(data[col].mode()[0], inplace=True)\\n                else:\\n                    data[col].fillna(\"missing\", inplace=True)\\n\\n        return data\\n\\n    # DATA SPLITTING\\n    def Data_splitting(self, X, y):\\n\\n        return train_test_split(\\n            X,\\n            y,\\n            test_size=0.2,\\n            random_state=42\\n        )\\n\\n    # PREPROCESSING (ENCODING + SCALING)\\n\\n    def Preprocess(self, X_train, X_test=None):\\n\\n        num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\\n        cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\\n\\n        self.preprocessor = ColumnTransformer(\\n            transformers=[\\n                (\"num\", StandardScaler(), num_cols),\\n                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)\\n            ]\\n        )\\n\\n        X_train_processed = self.preprocessor.fit_transform(X_train)\\n\\n        if X_test is not None:\\n            X_test_processed = self.preprocessor.transform(X_test)\\n            return X_train_processed, X_test_processed\\n\\n        return X_train_processed\\n\\n\\n    def model_design(self, data):\\n\\n        # ------------------------------\\n        # CLEANING\\n        # ------------------------------\\n        data = self.clean_data(data)\\n\\n        X = data.drop(columns=[self.target_column])\\n        y = data[self.target_column]\\n\\n        # ==================================================\\n        # TODO 1: TASK DETECTION\\n        # ASSIGNED TO: Shreyas\\n        # Use:\\n        # - y.dtype\\n        # - y.nunique()\\n        # Set:\\n        # self.task_type = \"classification\" or \"regression\"\\n        # ==================================================\\n        # self.task_type = ?\\n\\n\\n        # ------------------------------\\n        # SPLIT DATA\\n        # ------------------------------\\n        X_train, X_test, y_train, y_test = self.Data_splitting(X, y)\\n\\n        # ------------------------------\\n        # PREPROCESS DATA\\n        # ------------------------------\\n        X_train_p, X_test_p = self.Preprocess(X_train, X_test)\\n\\n\\n        # ==================================================\\n        # TODO 2: MODEL SELECTION\\n        # ASSIGNED TO: Gourav\\n        # Create a dictionary like:\\n        # models = {\"Model Name\": model_object}\\n        # Based on self.task_type\\n        # ==================================================\\n        # models = {}\\n\\n\\n        # ==================================================\\n        # TODO 3: MODEL TRAINING\\n        # ASSIGNED TO: Monish\\n        # For each model:\\n        # - fit(X_train_p, y_train)\\n        # - predict(X_test_p)\\n        # Store predictions:\\n        # predictions = {\"Model Name\": preds}\\n        # ==================================================\\n        # predictions = {}\\n\\n\\n        # ==================================================\\n        # TODO 4: MODEL EVALUATION\\n        # ASSIGNED TO:\\n        # Classification → Rajshekar\\n        # Regression     → Rahul\\n        # For each prediction:\\n        # - calculate metrics\\n        # - append dict to results list\\n        # ==================================================\\n        # results = []\\n\\n\\n        # ==================================================\\n        # TODO 5: MODEL COMPARISON\\n        # ASSIGNED TO: Seshadri\\n        # Steps:\\n        # - Convert results to DataFrame\\n        # - Sort by main metric\\n        # - Extract best and top-2 models\\n        # ==================================================\\n        # self.results_df = ?\\n        # best_model = ?\\n        # top_2_models = ?\\n        pass\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Package:\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, problem_statement=\"classification\", target_column=None):\n",
        "        self.problem_statement = problem_statement\n",
        "        self.target_column = target_column\n",
        "\n",
        "        self.preprocessor = None\n",
        "        self.best_model_obj = None\n",
        "        self.task_type = None\n",
        "        self.results_df = None\n",
        "\n",
        "\n",
        "    # Return Models\n",
        "    def return_models(self, problem_statement):\n",
        "\n",
        "        if problem_statement == \"classification\":\n",
        "            return {\n",
        "                \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "                \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "                \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "                \"SVC\": SVC()\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"Linear Regression\": LinearRegression(),\n",
        "                \"Ridge Regression\": Ridge(),\n",
        "                \"Lasso Regression\": Lasso(),\n",
        "                \"SVR\": SVR()\n",
        "            }\n",
        "\n",
        "\n",
        "    # Data Cleaning\n",
        "    def clean_data(self, data):\n",
        "\n",
        "        data = data.copy()\n",
        "        data = data.drop_duplicates()\n",
        "\n",
        "        for col in data.columns:\n",
        "            if data[col].dtype in [\"int64\", \"float64\"]:\n",
        "                data[col].fillna(data[col].mean(), inplace=True)\n",
        "            else:\n",
        "                if len(data[col].mode()) > 0:\n",
        "                    data[col].fillna(data[col].mode()[0], inplace=True)\n",
        "                else:\n",
        "                    data[col].fillna(\"missing\", inplace=True)\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "    # Data Splitting\n",
        "    def Data_splitting(self, X, y):\n",
        "\n",
        "        return train_test_split(\n",
        "            X,\n",
        "            y,\n",
        "            test_size=0.2,\n",
        "            random_state=42,\n",
        "            stratify=y if self.task_type == \"classification\" and y.nunique() > 1 else None\n",
        "        )\n",
        "\n",
        "\n",
        "    # Preprocessing\n",
        "    def Preprocess(self, X_train, X_test=None):\n",
        "\n",
        "        num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "        cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "        self.preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                (\"num\", StandardScaler(), num_cols),\n",
        "                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        X_train_processed = self.preprocessor.fit_transform(X_train)\n",
        "\n",
        "        if X_test is not None:\n",
        "            X_test_processed = self.preprocessor.transform(X_test)\n",
        "            return X_train_processed, X_test_processed\n",
        "\n",
        "        return X_train_processed\n",
        "\n",
        "\n",
        "    # ML Model Design (MAIN PIPELINE)\n",
        "    def model_design(self, data):\n",
        "\n",
        "        if self.target_column not in data.columns:\n",
        "            raise ValueError(\"Target column not found in dataset\")\n",
        "\n",
        "        # ------------------------\n",
        "        # Data Cleaning\n",
        "        # ------------------------\n",
        "        data = self.clean_data(data)\n",
        "\n",
        "        X = data.drop(columns=[self.target_column])\n",
        "        y = data[self.target_column]\n",
        "\n",
        "        # ------------------------\n",
        "        # Task Detection\n",
        "        # ------------------------\n",
        "        if y.dtype == \"object\" or y.nunique() <= 15:\n",
        "            self.task_type = \"classification\"\n",
        "        else:\n",
        "            self.task_type = \"regression\"\n",
        "\n",
        "        # ------------------------\n",
        "        # Train–Test Split\n",
        "        # ------------------------\n",
        "        X_train, X_test, y_train, y_test = self.Data_splitting(X, y)\n",
        "\n",
        "        # ------------------------\n",
        "        # Preprocessing\n",
        "        # ------------------------\n",
        "        X_train_processed, X_test_processed = self.Preprocess(X_train, X_test)\n",
        "\n",
        "        # ------------------------\n",
        "        # Model Selection\n",
        "        # ------------------------\n",
        "        models = self.return_models(self.task_type)\n",
        "\n",
        "        results = []\n",
        "        trained_models = {}\n",
        "\n",
        "        # ------------------------\n",
        "        # Model Training + Evaluation\n",
        "        # ------------------------\n",
        "        for name, model in models.items():\n",
        "\n",
        "            model.fit(X_train_processed, y_train)\n",
        "            preds = model.predict(X_test_processed)\n",
        "            trained_models[name] = model\n",
        "\n",
        "            if self.task_type == \"classification\":\n",
        "                metrics = {\n",
        "                    \"Model\": name,\n",
        "                    \"Accuracy\": accuracy_score(y_test, preds),\n",
        "                    \"Precision\": precision_score(y_test, preds, average=\"weighted\", zero_division=0),\n",
        "                    \"Recall\": recall_score(y_test, preds, average=\"weighted\", zero_division=0),\n",
        "                    \"F1 Score\": f1_score(y_test, preds, average=\"weighted\", zero_division=0)\n",
        "                }\n",
        "            else:\n",
        "                metrics = {\n",
        "                    \"Model\": name,\n",
        "                    \"R2 Score\": r2_score(y_test, preds),\n",
        "                    \"RMSE\": np.sqrt(mean_squared_error(y_test, preds)),\n",
        "                    \"MAE\": mean_absolute_error(y_test, preds)\n",
        "                }\n",
        "\n",
        "            results.append(metrics)\n",
        "\n",
        "        # ------------------------\n",
        "        # Model Comparison\n",
        "        # ------------------------\n",
        "        self.results_df = pd.DataFrame(results)\n",
        "\n",
        "        #if self.results_df.empty:\n",
        "         # raise ValueError(\"No models were successfully evaluated. Please check training step.\")\n",
        "\n",
        "        sort_col = \"F1 Score\" if self.task_type == \"classification\" else \"R2 Score\"\n",
        "        self.results_df = self.results_df.sort_values(by=sort_col, ascending=False)\n",
        "\n",
        "        best_model_name = self.results_df.iloc[0][\"Model\"]\n",
        "        self.best_model_obj = trained_models[best_model_name]\n",
        "\n",
        "        return {\n",
        "            \"task_type\": self.task_type,\n",
        "            \"results\": self.results_df,\n",
        "            \"best_model\": best_model_name,\n",
        "            \"top_2_models\": self.results_df.iloc[:2][\"Model\"].tolist()\n",
        "        }"
      ],
      "metadata": {
        "id": "S3QRgt6Q9OAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "LF3OKMO19YjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df[\"target\"] = data.target\n",
        "\n",
        "# Initialize your package\n",
        "pkg = Package(target_column=\"target\")\n",
        "\n",
        "# Run AutoML\n",
        "output = pkg.model_design(df)\n",
        "\n",
        "# View results\n",
        "print(\"Task Type:\", output[\"task_type\"])\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(output[\"results\"])\n",
        "print(\"\\nBest Model:\", output[\"best_model\"])\n",
        "print(\"Top 2 Models:\", output[\"top_2_models\"])\n"
      ],
      "metadata": {
        "id": "EmxoxGz2zjU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f02ec6-7c29-4d4f-f006-56ca954f6cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task Type: classification\n",
            "\n",
            "Model Comparison:\n",
            "                 Model  Accuracy  Precision    Recall  F1 Score\n",
            "0  Logistic Regression  0.982456   0.982456  0.982456  0.982456\n",
            "3                  SVC  0.982456   0.982456  0.982456  0.982456\n",
            "2        Random Forest  0.956140   0.956073  0.956140  0.956027\n",
            "1        Decision Tree  0.912281   0.916072  0.912281  0.913021\n",
            "\n",
            "Best Model: Logistic Regression\n",
            "Top 2 Models: ['Logistic Regression', 'SVC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "\n",
        "# DataFrame already available\n",
        "df = data.frame\n",
        "\n",
        "# Initialize your package\n",
        "pkg = Package(target_column=\"MedHouseVal\")\n",
        "\n",
        "# Run AutoML\n",
        "output = pkg.model_design(df)\n",
        "\n",
        "# View results\n",
        "print(\"Task Type:\", output[\"task_type\"])\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(output[\"results\"])\n",
        "print(\"\\nBest Model:\", output[\"best_model\"])\n",
        "print(\"Top 2 Models:\", output[\"top_2_models\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlOihv61-DYK",
        "outputId": "19777cad-62dc-4e6a-c6b1-ad38feacbad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task Type: regression\n",
            "\n",
            "Model Comparison:\n",
            "               Model  R2 Score      RMSE       MAE\n",
            "3                SVR  0.727563  0.597498  0.398599\n",
            "1   Ridge Regression  0.575816  0.745557  0.533193\n",
            "0  Linear Regression  0.575788  0.745581  0.533200\n",
            "2   Lasso Regression -0.000219  1.144856  0.906069\n",
            "\n",
            "Best Model: SVR\n",
            "Top 2 Models: ['SVR', 'Ridge Regression']\n"
          ]
        }
      ]
    }
  ]
}